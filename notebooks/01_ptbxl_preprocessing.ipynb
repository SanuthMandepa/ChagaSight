{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8789f402",
   "metadata": {},
   "source": [
    "# 01 ‚Äì PTB-XL Data Loading and Preprocessing\n",
    "\n",
    "This notebook loads and explores the PTB-XL dataset, verifies metadata,\n",
    "and prepares standardised numpy arrays for model training.\n",
    "\n",
    "**Official split rule**\n",
    "- Train ‚Üí folds 1 ‚Äì 8  \n",
    "- Validation ‚Üí fold 9  \n",
    "- Test ‚Üí fold 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd6e4147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment setup check:\n",
      "Python version : 3.12.8\n",
      "Working folder : d:\\IIT\\L6\\FYP\\chagas-ecg-detection\\notebooks\n",
      "üß† GPU detected : NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "CUDA version   : 11.8\n",
      "PyTorch build  : 2.7.1+cu118\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 00. Environment and GPU Check\n",
    "# ======================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"‚úÖ Environment setup check:\")\n",
    "print(f\"Python version : {sys.version.split()[0]}\")\n",
    "print(f\"Working folder : {os.getcwd()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"üß† GPU detected : {device_name}\")\n",
    "    print(f\"CUDA version   : {torch.version.cuda}\")\n",
    "    print(f\"PyTorch build  : {torch.__version__}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected ‚Äî running on CPU.\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd0c616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "‚úÖ PTB-XL metadata loaded successfully\n",
      "File path : D:\\IIT\\L6\\FYP\\chagas-ecg-detection\\data\\raw\\ptbxl\\ptbxl_database.csv\n",
      "Shape     : 21799 rows √ó 28 columns\n",
      "Columns   : ecg_id, patient_id, age, sex, height, weight, nurse, site, device, recording_date, report, scp_codes, heart_axis, infarction_stadium1, infarction_stadium2, validated_by, second_opinion, initial_autogenerated_report, validated_by_human, baseline_drift, static_noise, burst_noise, electrodes_problems, extra_beats, pacemaker, strat_fold, filename_lr, filename_hr\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>nurse</th>\n",
       "      <th>site</th>\n",
       "      <th>device</th>\n",
       "      <th>recording_date</th>\n",
       "      <th>report</th>\n",
       "      <th>scp_codes</th>\n",
       "      <th>heart_axis</th>\n",
       "      <th>infarction_stadium1</th>\n",
       "      <th>infarction_stadium2</th>\n",
       "      <th>validated_by</th>\n",
       "      <th>second_opinion</th>\n",
       "      <th>initial_autogenerated_report</th>\n",
       "      <th>validated_by_human</th>\n",
       "      <th>baseline_drift</th>\n",
       "      <th>static_noise</th>\n",
       "      <th>burst_noise</th>\n",
       "      <th>electrodes_problems</th>\n",
       "      <th>extra_beats</th>\n",
       "      <th>pacemaker</th>\n",
       "      <th>strat_fold</th>\n",
       "      <th>filename_lr</th>\n",
       "      <th>filename_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15709.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-09 09:17:34</td>\n",
       "      <td>sinusrhythmus periphere niederspannung</td>\n",
       "      <td>{'NORM': 100.0, 'LVOLT': 0.0, 'SR': 0.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, I-V1,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00001_lr</td>\n",
       "      <td>records500/00000/00001_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13243.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-14 12:55:37</td>\n",
       "      <td>sinusbradykardie sonst normales ekg</td>\n",
       "      <td>{'NORM': 80.0, 'SBRAD': 0.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>records100/00000/00002_lr</td>\n",
       "      <td>records500/00000/00002_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20372.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-15 12:49:10</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>records100/00000/00003_lr</td>\n",
       "      <td>records500/00000/00003_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17014.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-15 13:44:57</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>, II,III,AVF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00004_lr</td>\n",
       "      <td>records500/00000/00004_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17448.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-17 10:43:15</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>, III,AVR,AVF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>records100/00000/00005_lr</td>\n",
       "      <td>records500/00000/00005_hr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ecg_id  patient_id   age  sex  height  weight  nurse  site     device  \\\n",
       "0       1     15709.0  56.0    1     NaN    63.0    2.0   0.0  CS-12   E   \n",
       "1       2     13243.0  19.0    0     NaN    70.0    2.0   0.0  CS-12   E   \n",
       "2       3     20372.0  37.0    1     NaN    69.0    2.0   0.0  CS-12   E   \n",
       "3       4     17014.0  24.0    0     NaN    82.0    2.0   0.0  CS-12   E   \n",
       "4       5     17448.0  19.0    1     NaN    70.0    2.0   0.0  CS-12   E   \n",
       "\n",
       "        recording_date                                  report  \\\n",
       "0  1984-11-09 09:17:34  sinusrhythmus periphere niederspannung   \n",
       "1  1984-11-14 12:55:37     sinusbradykardie sonst normales ekg   \n",
       "2  1984-11-15 12:49:10              sinusrhythmus normales ekg   \n",
       "3  1984-11-15 13:44:57              sinusrhythmus normales ekg   \n",
       "4  1984-11-17 10:43:15              sinusrhythmus normales ekg   \n",
       "\n",
       "                                  scp_codes heart_axis infarction_stadium1  \\\n",
       "0  {'NORM': 100.0, 'LVOLT': 0.0, 'SR': 0.0}        NaN                 NaN   \n",
       "1              {'NORM': 80.0, 'SBRAD': 0.0}        NaN                 NaN   \n",
       "2                {'NORM': 100.0, 'SR': 0.0}        NaN                 NaN   \n",
       "3                {'NORM': 100.0, 'SR': 0.0}        NaN                 NaN   \n",
       "4                {'NORM': 100.0, 'SR': 0.0}        NaN                 NaN   \n",
       "\n",
       "  infarction_stadium2  validated_by  second_opinion  \\\n",
       "0                 NaN           NaN           False   \n",
       "1                 NaN           NaN           False   \n",
       "2                 NaN           NaN           False   \n",
       "3                 NaN           NaN           False   \n",
       "4                 NaN           NaN           False   \n",
       "\n",
       "   initial_autogenerated_report  validated_by_human  baseline_drift  \\\n",
       "0                         False                True             NaN   \n",
       "1                         False                True             NaN   \n",
       "2                         False                True             NaN   \n",
       "3                         False                True    , II,III,AVF   \n",
       "4                         False                True   , III,AVR,AVF   \n",
       "\n",
       "  static_noise burst_noise electrodes_problems extra_beats pacemaker  \\\n",
       "0    , I-V1,           NaN                 NaN         NaN       NaN   \n",
       "1          NaN         NaN                 NaN         NaN       NaN   \n",
       "2          NaN         NaN                 NaN         NaN       NaN   \n",
       "3          NaN         NaN                 NaN         NaN       NaN   \n",
       "4          NaN         NaN                 NaN         NaN       NaN   \n",
       "\n",
       "   strat_fold                filename_lr                filename_hr  \n",
       "0           3  records100/00000/00001_lr  records500/00000/00001_hr  \n",
       "1           2  records100/00000/00002_lr  records500/00000/00002_hr  \n",
       "2           5  records100/00000/00003_lr  records500/00000/00003_hr  \n",
       "3           3  records100/00000/00004_lr  records500/00000/00004_hr  \n",
       "4           4  records100/00000/00005_lr  records500/00000/00005_hr  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 01. Load and Verify PTB-XL Metadata\n",
    "# ======================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# --- Dataset path ---\n",
    "DATA_PATH = r\"D:\\IIT\\L6\\FYP\\chagas-ecg-detection\\data\\raw\\ptbxl\"\n",
    "META_FILE = os.path.join(DATA_PATH, \"ptbxl_database.csv\")\n",
    "\n",
    "# --- Verify file existence ---\n",
    "if not os.path.exists(META_FILE):\n",
    "    raise FileNotFoundError(f\"‚ùå Metadata file not found: {META_FILE}\")\n",
    "\n",
    "# --- Load metadata ---\n",
    "df = pd.read_csv(META_FILE)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"‚úÖ PTB-XL metadata loaded successfully\")\n",
    "print(f\"File path : {META_FILE}\")\n",
    "print(f\"Shape     : {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "print(\"Columns   :\", \", \".join(df.columns))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a584eaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Processed data will be saved to: D:\\IIT\\L6\\FYP\\chagas-ecg-detection\\data\\processed\\ptbxl\n",
      "‚úÖ Loaded SCP mapping for 44 diagnostic codes.\n",
      "‚öôÔ∏è  Parallel processing all ECG signals ...\n",
      "üß© Using 16 CPU threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21799/21799 [02:31<00:00, 143.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished processing 21799 ECGs successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 02. Preprocess PTB-XL Records ‚Üí Normalized Arrays\n",
    "# ======================================================\n",
    "\n",
    "import ast\n",
    "import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import multiprocessing\n",
    "\n",
    "# --- Output directory ---\n",
    "PROCESSED_DIR = os.path.join(\n",
    "    r\"D:\\IIT\\L6\\FYP\\chagas-ecg-detection\\data\\processed\", \"ptbxl\"\n",
    ")\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "print(f\"üìÅ Processed data will be saved to: {PROCESSED_DIR}\")\n",
    "\n",
    "# --- Load SCP mapping (diagnostic codes ‚Üí superclass) ---\n",
    "SCP_FILE = os.path.join(DATA_PATH, \"scp_statements.csv\")\n",
    "scp_df = pd.read_csv(SCP_FILE, index_col=0)\n",
    "scp_df = scp_df[scp_df['diagnostic'] == 1]\n",
    "scp_map = scp_df['diagnostic_class'].to_dict()\n",
    "print(f\"‚úÖ Loaded SCP mapping for {len(scp_map)} diagnostic codes.\")\n",
    "\n",
    "# --- Worker: read + normalize + label one record ---\n",
    "def process_record(idx):\n",
    "    try:\n",
    "        rel = df.loc[idx, \"filename_lr\"]\n",
    "        full = os.path.join(DATA_PATH, rel)\n",
    "        record = wfdb.rdrecord(full)\n",
    "        signal = record.p_signal.T  # (12, samples)\n",
    "\n",
    "        # Normalize per-lead to [-1, 1]\n",
    "        smin, smax = signal.min(1, keepdims=True), signal.max(1, keepdims=True)\n",
    "        denom = np.where((smax - smin) == 0, 1.0, (smax - smin))\n",
    "        signal_norm = 2 * (signal - smin) / denom - 1\n",
    "\n",
    "        # Map SCP codes ‚Üí superclass label\n",
    "        scp_dict = ast.literal_eval(df.loc[idx, \"scp_codes\"])\n",
    "        relevant = {k: v for k, v in scp_dict.items() if k in scp_map}\n",
    "        if not relevant:\n",
    "            label = \"UNKNOWN\"\n",
    "        else:\n",
    "            superclasses = [scp_map[k] for k in relevant.keys()]\n",
    "            label = max(set(superclasses), key=superclasses.count)\n",
    "\n",
    "        return signal_norm.astype(np.float32), label, df.loc[idx, \"strat_fold\"]\n",
    "    except Exception as e:\n",
    "        return None, None, None\n",
    "\n",
    "# --- Parallel processing ---\n",
    "print(\"‚öôÔ∏è  Parallel processing all ECG signals ...\")\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "print(f\"üß© Using {num_workers} CPU threads\")\n",
    "\n",
    "signals, labels, folds = [], [], []\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    futures = {executor.submit(process_record, i): i for i in range(len(df))}\n",
    "    for fut in tqdm.tqdm(as_completed(futures), total=len(df)):\n",
    "        sig, lbl, fld = fut.result()\n",
    "        if sig is not None:\n",
    "            signals.append(sig)\n",
    "            labels.append(lbl)\n",
    "            folds.append(fld)\n",
    "\n",
    "print(f\"‚úÖ Finished processing {len(signals)} ECGs successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6929f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Saved processed NumPy arrays:\n",
      "    test_labels.npy\n",
      "    test_signals.npy\n",
      "    train_labels.npy\n",
      "    train_signals.npy\n",
      "    val_labels.npy\n",
      "    val_signals.npy\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 03. Split and Save Preprocessed Arrays\n",
    "# ======================================================\n",
    "\n",
    "signals = np.array(signals, dtype=object)\n",
    "labels  = np.array(labels)\n",
    "folds   = np.array(folds)\n",
    "\n",
    "# --- PTB-XL official folds ---\n",
    "train_mask = np.isin(folds, list(range(1, 9)))  # folds 1‚Äì8\n",
    "val_mask   = folds == 9\n",
    "test_mask  = folds == 10\n",
    "\n",
    "np.save(os.path.join(PROCESSED_DIR, \"train_signals.npy\"), signals[train_mask])\n",
    "np.save(os.path.join(PROCESSED_DIR, \"val_signals.npy\"),   signals[val_mask])\n",
    "np.save(os.path.join(PROCESSED_DIR, \"test_signals.npy\"),  signals[test_mask])\n",
    "np.save(os.path.join(PROCESSED_DIR, \"train_labels.npy\"),  labels[train_mask])\n",
    "np.save(os.path.join(PROCESSED_DIR, \"val_labels.npy\"),    labels[val_mask])\n",
    "np.save(os.path.join(PROCESSED_DIR, \"test_labels.npy\"),   labels[test_mask])\n",
    "\n",
    "print(\"\\n‚úÖ Saved processed NumPy arrays:\")\n",
    "for f in os.listdir(PROCESSED_DIR):\n",
    "    print(\"   \", f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3eeea9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ TRAIN SET\n",
      "   Signals: 17418 | Labels: 17418\n",
      "   ‚úÖ Integrity OK\n",
      "   Example shape : (12, 1000)\n",
      "   Example label : NORM\n",
      "\n",
      "üì¶ VAL SET\n",
      "   Signals: 2183 | Labels: 2183\n",
      "   ‚úÖ Integrity OK\n",
      "   Example shape : (12, 1000)\n",
      "   Example label : MI\n",
      "\n",
      "üì¶ TEST SET\n",
      "   Signals: 2198 | Labels: 2198\n",
      "   ‚úÖ Integrity OK\n",
      "   Example shape : (12, 1000)\n",
      "   Example label : NORM\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 04. Verify Processed PTB-XL Arrays\n",
    "# ======================================================\n",
    "\n",
    "import collections\n",
    "\n",
    "expected = [\n",
    "    \"train_signals.npy\", \"val_signals.npy\", \"test_signals.npy\",\n",
    "    \"train_labels.npy\",  \"val_labels.npy\",  \"test_labels.npy\"\n",
    "]\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    x = np.load(os.path.join(PROCESSED_DIR, f\"{split}_signals.npy\"), allow_pickle=True)\n",
    "    y = np.load(os.path.join(PROCESSED_DIR, f\"{split}_labels.npy\"), allow_pickle=True)\n",
    "\n",
    "    print(f\"\\nüì¶ {split.upper()} SET\")\n",
    "    print(f\"   Signals: {len(x)} | Labels: {len(y)}\")\n",
    "    if len(x) == len(y):\n",
    "        print(\"   ‚úÖ Integrity OK\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Mismatch detected!\")\n",
    "\n",
    "    print(f\"   Example shape : {x[0].shape}\")\n",
    "    print(f\"   Example label : {y[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e23986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß© Converting train split ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17418/17418 [00:48<00:00, 356.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß© Converting val split ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2183/2183 [00:04<00:00, 455.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß© Converting test split ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2198/2198 [00:04<00:00, 501.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Conversion complete ‚Äî You can now delete *_signals.npy to free space.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 05. Convert Large Arrays into Per-Record .npy Files\n",
    "# ============================================================\n",
    "from pathlib import Path\n",
    "import tqdm\n",
    "\n",
    "DATA_DIR = Path(PROCESSED_DIR)\n",
    "OUT_DIR  = DATA_DIR / \"records_split\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    print(f\"\\nüß© Converting {split} split ...\")\n",
    "    x = np.load(DATA_DIR / f\"{split}_signals.npy\", allow_pickle=True)\n",
    "    y = np.load(DATA_DIR / f\"{split}_labels.npy\", allow_pickle=True)\n",
    "\n",
    "    split_dir = OUT_DIR / split\n",
    "    split_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for i in tqdm.trange(len(x)):\n",
    "        np.save(split_dir / f\"{i:05d}.npy\", x[i].astype(np.float32))\n",
    "\n",
    "    np.save(split_dir / \"labels.npy\", y)\n",
    "\n",
    "print(\"\\n‚úÖ Conversion complete ‚Äî You can now delete *_signals.npy to free space.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18be9d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 17418 signals | 17418 labels | example 00000.npy\n",
      "  VAL: 2183 signals | 2183 labels | example 00000.npy\n",
      " TEST: 2198 signals | 2198 labels | example 00000.npy\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 06. Verify per-record split folder\n",
    "# ============================================================\n",
    "ROOT = Path(PROCESSED_DIR) / \"records_split\"\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    split_dir = ROOT / split\n",
    "    labels = np.load(split_dir / \"labels.npy\", allow_pickle=True)\n",
    "    files = sorted([f for f in split_dir.glob(\"*.npy\") if f.name != \"labels.npy\"])\n",
    "    print(f\"{split.upper():>5}: {len(files)} signals | {len(labels)} labels | example {files[0].name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
