{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e76297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "VRAM (GB): 6.44\n",
      "PyTorch: 2.7.1+cu118\n",
      "CUDA: 11.8\n",
      "\n",
      "======================================================================\n",
      "PROJECT_ROOT: d:\\IIT\\L6\\FYP\\ChagaSight\n",
      "DATA_DIR: d:\\IIT\\L6\\FYP\\ChagaSight\\data\\processed\n",
      "EXP_DIR: d:\\IIT\\L6\\FYP\\ChagaSight\\experiments\\vit_contour_research_approved\\20260112_120757\n",
      "======================================================================\n",
      "\n",
      "‚úì Cell 1 initialized in 0.00s\n"
     ]
    }
   ],
   "source": [
    "import time, random, sys, os\n",
    "import subprocess\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR, SequentialLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, f1_score,\n",
    "    accuracy_score, precision_score, recall_score, confusion_matrix,\n",
    "    roc_curve, auc\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ---- Reproducibility ----\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# ---- Device ----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM (GB): {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f}\")\n",
    "    print(f\"PyTorch: {torch.__version__}\")\n",
    "    print(f\"CUDA: {torch.version.cuda}\")\n",
    "\n",
    "\n",
    "# ---- GPU Monitoring (background thread) ----\n",
    "def monitor_gpu():\n",
    "    try:\n",
    "        subprocess.Popen([\n",
    "            'nvidia-smi',\n",
    "            '--query-gpu=timestamp,name,utilization.gpu,memory.used,memory.total',\n",
    "            '--format=csv', '-l', '10'\n",
    "        ])\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: nvidia-smi not found ‚Äì GPU monitoring skipped.\")\n",
    "\n",
    "\n",
    "threading.Thread(target=monitor_gpu, daemon=True).start()\n",
    "\n",
    "\n",
    "# ---- Paths (auto-detect project root) ----\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data\").exists():\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_project_root(Path.cwd())\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "\n",
    "# ---- Experiment ----\n",
    "EXP_NAME = \"vit_contour_research_approved\"\n",
    "RUN_ID = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "EXP_DIR = PROJECT_ROOT / \"experiments\" / EXP_NAME / RUN_ID\n",
    "EXP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")\n",
    "print(f\"EXP_DIR: {EXP_DIR}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "cell_start = time.time()\n",
    "print(f\"‚úì Cell 1 initialized in {time.time() - cell_start:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7676b16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ptbxl: 21799 records\n",
      "Loaded sami_trop: 1631 records\n",
      "Loaded code15: 39798 records\n",
      "‚úì No duplicate IDs\n",
      "\n",
      "Label statistics:\n",
      "  Min: 0.0000\n",
      "  Max: 1.0000\n",
      "  Mean: 0.1595\n",
      "  NaN count: 0\n",
      "\n",
      "Class distribution by dataset:\n",
      "  ptbxl        | Pos:     0 | Neg: 21799 | Soft:     0 | Total: 21799\n",
      "  sami_trop    | Pos:  1631 | Neg:     0 | Soft:     0 | Total:  1631\n",
      "  code15       | Pos:   819 | Neg: 38979 | Soft: 39798 | Total: 39798\n",
      "\n",
      "  GLOBAL: 2450 positive, 60778 negative (ratio: 24.8x imbalance)\n",
      "  ‚ö†Ô∏è Severe class imbalance detected! Weighted loss is CRITICAL.\n",
      "\n",
      "‚úì All image files exist\n",
      "\n",
      "Creating stratified train/val/test splits...\n",
      "Train: 50582 (1960 positive)\n",
      "Val:   6323 (245 positive)\n",
      "Test:  6323 (245 positive)\n",
      "‚úì No data leakage\n",
      "\n",
      "‚úì Cell 2 completed in 18.73s\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "# ---- Load all metadata ----\n",
    "datasets = [\"ptbxl\", \"sami_trop\", \"code15\"]\n",
    "dfs = []\n",
    "\n",
    "for ds in datasets:\n",
    "    csv_path = DATA_DIR / \"metadata\" / f\"{ds}_metadata.csv\"\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing: {csv_path}\")\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    df[\"dataset\"] = ds\n",
    "    df[\"label\"] = df[\"label\"].astype(float)\n",
    "    dfs.append(df)\n",
    "    print(f\"Loaded {ds}: {len(df)} records\")\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# ---- TEST 1: Check for duplicates ----\n",
    "duplicate_ids = df_all[df_all.duplicated(subset=['id'], keep=False)]\n",
    "if len(duplicate_ids) > 0:\n",
    "    print(f\"‚ö†Ô∏è WARNING: {len(duplicate_ids)} duplicate IDs found\")\n",
    "else:\n",
    "    print(\"‚úì No duplicate IDs\")\n",
    "\n",
    "# ---- TEST 2: Check label values ----\n",
    "print(f\"\\nLabel statistics:\")\n",
    "print(f\"  Min: {df_all['label'].min():.4f}\")\n",
    "print(f\"  Max: {df_all['label'].max():.4f}\")\n",
    "print(f\"  Mean: {df_all['label'].mean():.4f}\")\n",
    "print(f\"  NaN count: {df_all['label'].isna().sum()}\")\n",
    "\n",
    "# Drop any NaN labels\n",
    "df_all = df_all.dropna(subset=['label']).reset_index(drop=True)\n",
    "\n",
    "# ---- TEST 3: Class distribution per dataset ----\n",
    "print(f\"\\nClass distribution by dataset:\")\n",
    "for ds in datasets:\n",
    "    ds_df = df_all[df_all['dataset'] == ds]\n",
    "    pos_count = (ds_df['label'] > 0.5).sum()\n",
    "    neg_count = (ds_df['label'] <= 0.5).sum()\n",
    "    soft_count = ((ds_df['label'] > 0.1) & (ds_df['label'] < 0.9)).sum()\n",
    "    print(f\"  {ds:12} | Pos: {pos_count:5} | Neg: {neg_count:5} | Soft: {soft_count:5} | Total: {len(ds_df):5}\")\n",
    "\n",
    "# Global distribution\n",
    "pos_total = (df_all['label'] > 0.5).sum()\n",
    "neg_total = (df_all['label'] <= 0.5).sum()\n",
    "imbalance_ratio = neg_total / (pos_total + 1e-6)\n",
    "print(f\"\\n  GLOBAL: {pos_total} positive, {neg_total} negative (ratio: {imbalance_ratio:.1f}x imbalance)\")\n",
    "print(f\"  ‚ö†Ô∏è Severe class imbalance detected! Weighted loss is CRITICAL.\\n\")\n",
    "\n",
    "# ---- TEST 4: Check image file existence ----\n",
    "def img_exists(p):\n",
    "    \"\"\"Cross-platform path checking\"\"\"\n",
    "    clean_path = str(p).replace(\"\\\\\", \"/\")\n",
    "    full_path = (PROJECT_ROOT / Path(clean_path)).resolve()\n",
    "    return full_path.exists()\n",
    "\n",
    "exists_mask = df_all[\"img_path\"].apply(img_exists)\n",
    "missing_count = (~exists_mask).sum()\n",
    "\n",
    "if missing_count > 0:\n",
    "    print(f\"‚ö†Ô∏è WARNING: {missing_count} missing image files\")\n",
    "    df_all = df_all.loc[exists_mask].reset_index(drop=True)\n",
    "    print(f\"Dropped {missing_count} rows. Remaining: {len(df_all)}\")\n",
    "else:\n",
    "    print(\"‚úì All image files exist\")\n",
    "\n",
    "# ---- Create binary labels for metrics only ----\n",
    "df_all[\"label_bin\"] = (df_all[\"label\"] > 0.5).astype(int)\n",
    "\n",
    "# ---- TEST 5: Stratified splits with distribution check ----\n",
    "print(f\"\\nCreating stratified train/val/test splits...\")\n",
    "train_df, temp_df = train_test_split(\n",
    "    df_all, test_size=0.2, stratify=df_all[\"label_bin\"], random_state=SEED\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.5, stratify=temp_df[\"label_bin\"], random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_df)} ({(train_df['label_bin']==1).sum()} positive)\")\n",
    "print(f\"Val:   {len(val_df)} ({(val_df['label_bin']==1).sum()} positive)\")\n",
    "print(f\"Test:  {len(test_df)} ({(test_df['label_bin']==1).sum()} positive)\")\n",
    "\n",
    "# Check for leakage\n",
    "overlap = set(train_df['id']) & set(val_df['id']) | set(train_df['id']) & set(test_df['id'])\n",
    "if len(overlap) > 0:\n",
    "    raise RuntimeError(f\"Data leakage detected! {len(overlap)} overlapping IDs\")\n",
    "print(\"‚úì No data leakage\")\n",
    "\n",
    "print(f\"\\n‚úì Cell 2 completed in {time.time() - cell_start:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8a5552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì FULL MODE - Using all 50582 training samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SET THIS TO True FOR QUICK TEST (5 min), False FOR FULL TRAINING (3 hours)\n",
    "USE_SAMPLE = False\n",
    "SAMPLE_FRACTION = 0.01  # 0.01% of data = ~50 samples\n",
    "\n",
    "if USE_SAMPLE:\n",
    "    print(f\"\\n‚ö†Ô∏è  SAMPLE MODE ENABLED (testing on {SAMPLE_FRACTION*100:.3f}% of data)\")\n",
    "    \n",
    "    n_samples_train = max(32, int(len(train_df) * SAMPLE_FRACTION))\n",
    "    n_samples_val = max(16, int(len(val_df) * SAMPLE_FRACTION))\n",
    "    n_samples_test = max(16, int(len(test_df) * SAMPLE_FRACTION))\n",
    "    \n",
    "    train_df = train_df.sample(n=n_samples_train, random_state=SEED).reset_index(drop=True)\n",
    "    val_df = val_df.sample(n=n_samples_val, random_state=SEED).reset_index(drop=True)\n",
    "    test_df = test_df.sample(n=n_samples_test, random_state=SEED).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"  Train: {len(train_df)} ({(train_df['label_bin']==1).sum()} positive)\")\n",
    "    print(f\"  Val:   {len(val_df)} ({(val_df['label_bin']==1).sum()} positive)\")\n",
    "    print(f\"  Test:  {len(test_df)} ({(test_df['label_bin']==1).sum()} positive)\")\n",
    "    print(f\"  Expected training time: ~2-3 minutes\\n\")\n",
    "else:\n",
    "    print(f\"\\n‚úì FULL MODE - Using all {len(train_df)} training samples\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee6cade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets with validation...\n",
      "  Validating dataset of 50582 samples...\n",
      "  ‚úì First 10 samples validated (range: [-1, 1])\n",
      "  Validating dataset of 6323 samples...\n",
      "  ‚úì First 10 samples validated (range: [-1, 1])\n",
      "  Validating dataset of 6323 samples...\n",
      "  ‚úì First 10 samples validated (range: [-1, 1])\n",
      "\n",
      "Class weights:\n",
      "  Positive weight: 24.81 (compensate for 48622/1960 imbalance)\n",
      "  Negative weight: 1.0\n",
      "\n",
      "First batch check:\n",
      "  Shape: torch.Size([16, 3, 24, 2048]) (expect [16, 3, 24, 2048])\n",
      "  Range: [-1.000, 0.992] (expect [-1, 1])\n",
      "  Labels: [0.0, 0.20000000298023224, 0.0, 0.20000000298023224, 0.0] (expect values in [0, 1])\n",
      "  Label dtype: torch.float32\n",
      "  ‚úì First batch validation passed\n",
      "\n",
      "‚úì Cell 3 completed in 11.34s\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "class ECGImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads ECG 2D contour images with full validation.\n",
    "    ‚≠ê FIXED: Handles BOTH uint8 [0,255] and float32 [-3,3] ranges\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, validate_first=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_paths = [(PROJECT_ROOT / Path(str(p))).resolve() \n",
    "                         for p in self.df[\"img_path\"]]\n",
    "        self.labels = self.df[\"label\"].astype(np.float32).values\n",
    "        \n",
    "        if validate_first:\n",
    "            print(f\"  Validating dataset of {len(self)} samples...\")\n",
    "            self._validate_first_n_samples(n=min(10, len(self)))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        try:\n",
    "            img = np.load(self.img_paths[idx]).astype(np.float32)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to load {self.img_paths[idx]}: {e}\")\n",
    "        \n",
    "        # TEST: Shape validation\n",
    "        if img.shape != (3, 24, 2048):\n",
    "            raise ValueError(f\"Invalid shape {img.shape} at {self.img_paths[idx]}\")\n",
    "        \n",
    "        # TEST: NaN/Inf check\n",
    "        if np.isnan(img).any():\n",
    "            raise ValueError(f\"NaN values in {self.img_paths[idx]}\")\n",
    "        if np.isinf(img).any():\n",
    "            raise ValueError(f\"Inf values in {self.img_paths[idx]}\")\n",
    "        \n",
    "        # ‚≠ê FIXED: Handle BOTH uint8 [0,255] and float32 [-3,3]\n",
    "        if img.max() > 4:  # Likely uint8 [0,255]\n",
    "            # Convert from [0,255] to [-1,1]\n",
    "            img = (img.astype(np.float32) - 128.0) / 128.0\n",
    "        else:  # Already normalized [-3,3]\n",
    "            # Clip and normalize to [-1,1]\n",
    "            img = np.clip(img, -3, 3)\n",
    "            img = img / 3.0\n",
    "        \n",
    "        # Convert to tensor\n",
    "        img = torch.from_numpy(img)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        \n",
    "        return img, label\n",
    "    \n",
    "    def _validate_first_n_samples(self, n=10):\n",
    "        \"\"\"Validate first n samples for sanity\"\"\"\n",
    "        for idx in range(min(n, len(self))):\n",
    "            try:\n",
    "                img, label = self[idx]\n",
    "                assert img.shape == (3, 24, 2048), f\"Shape mismatch at {idx}: {img.shape}\"\n",
    "                assert img.min() >= -1.1 and img.max() <= 1.1, f\"Range mismatch at {idx}: [{img.min():.2f}, {img.max():.2f}]\"\n",
    "                assert not torch.isnan(img).any(), f\"NaN in tensor at {idx}\"\n",
    "                assert label.item() >= 0 and label.item() <= 1, f\"Invalid label at {idx}: {label.item()}\"\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"Validation failed at sample {idx}: {e}\")\n",
    "        print(f\"  ‚úì First {n} samples validated (range: [-1, 1])\")\n",
    "\n",
    "# Create datasets with validation\n",
    "print(f\"Creating datasets with validation...\")\n",
    "train_ds = ECGImageDataset(train_df, validate_first=True)\n",
    "val_ds = ECGImageDataset(val_df, validate_first=True)\n",
    "test_ds = ECGImageDataset(test_df, validate_first=True)\n",
    "\n",
    "# ---- Compute class weights for weighted loss ----\n",
    "pos_count = (train_df['label'] > 0.5).sum()\n",
    "neg_count = (train_df['label'] <= 0.5).sum()\n",
    "pos_weight = neg_count / (pos_count + 1e-6)\n",
    "\n",
    "print(f\"\\nClass weights:\")\n",
    "print(f\"  Positive weight: {pos_weight:.2f} (compensate for {neg_count}/{pos_count} imbalance)\")\n",
    "print(f\"  Negative weight: 1.0\")\n",
    "\n",
    "# ---- DataLoaders (Windows-safe, no multiprocessing delays) ----\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, \n",
    "                         num_workers=0, pin_memory=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
    "                       num_workers=0, pin_memory=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False,\n",
    "                        num_workers=0, pin_memory=False)\n",
    "\n",
    "# ---- Sanity check: First batch ----\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "print(f\"\\nFirst batch check:\")\n",
    "print(f\"  Shape: {x_batch.shape} (expect [16, 3, 24, 2048])\")\n",
    "print(f\"  Range: [{x_batch.min().item():.3f}, {x_batch.max().item():.3f}] (expect [-1, 1])\")\n",
    "print(f\"  Labels: {y_batch[:5].tolist()} (expect values in [0, 1])\")\n",
    "print(f\"  Label dtype: {y_batch.dtype}\")\n",
    "\n",
    "assert x_batch.shape == (batch_size, 3, 24, 2048), \"Batch shape mismatch!\"\n",
    "assert not torch.isnan(x_batch).any(), \"NaN in batch!\"\n",
    "assert x_batch.min() >= -1.1 and x_batch.max() <= 1.1, f\"Range mismatch: [{x_batch.min():.2f}, {x_batch.max():.2f}]\"\n",
    "print(\"  ‚úì First batch validation passed\")\n",
    "\n",
    "print(f\"\\n‚úì Cell 3 completed in {time.time() - cell_start:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1989dd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT Model parameters: 38,224,897\n",
      "Model device: cuda:0\n",
      "‚úì Forward pass check passed\n",
      "  Logits shape: torch.Size([2, 1]), range: [-0.95, -0.39]\n",
      "  Features shape: torch.Size([2, 512]), range: [-3.33, 2.96]\n",
      "\n",
      "‚úì Cell 4 completed in 0.44s\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "class ViTClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Vision Transformer for 2D ECG images (3x24x2048).\n",
    "    Implements AoL (Aggregation of Layers) for improved performance.\n",
    "    \n",
    "    Architecture:\n",
    "    - Patch embedding: (3, 24, 2048) ‚Üí (512, 3, 128) ‚Üí flattened (384, 512)\n",
    "    - 12 transformer blocks\n",
    "    - CLS token aggregation across all layers (AoL)\n",
    "    - Classification head\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, patch_h=8, patch_w=16, embed_dim=512, \n",
    "                 depth=12, heads=8, mlp_ratio=4.0, dropout=0.15):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.patch_h = patch_h\n",
    "        self.patch_w = patch_w\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # ---- Patch embedding (Conv2d for efficiency) ----\n",
    "        self.patch_embed = nn.Conv2d(3, embed_dim, kernel_size=(patch_h, patch_w),\n",
    "                                     stride=(patch_h, patch_w))\n",
    "        \n",
    "        # Expected patches: (24 / 8) * (2048 / 16) = 3 * 128 = 384\n",
    "        num_patches = (24 // patch_h) * (2048 // patch_w)\n",
    "        \n",
    "        # ---- Position embedding + CLS token ----\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, num_patches + 1, embed_dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "        \n",
    "        # ---- Transformer encoder (12 blocks) ----\n",
    "        self.blocks = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=embed_dim,\n",
    "                nhead=heads,\n",
    "                dim_feedforward=int(embed_dim * mlp_ratio),\n",
    "                dropout=dropout,\n",
    "                activation='gelu',\n",
    "                batch_first=True\n",
    "            ) for _ in range(depth)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        # ---- Classification head ----\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(embed_dim, 1)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        nn.init.normal_(self.pos_embed, std=0.02)\n",
    "        nn.init.normal_(self.cls_token, std=0.02)\n",
    "    \n",
    "    def forward(self, x, return_feats=False):\n",
    "        \"\"\"\n",
    "        Forward pass with AoL.\n",
    "        \n",
    "        Args:\n",
    "            x: (B, 3, 24, 2048)\n",
    "            return_feats: If True, return feature vectors (for alignment)\n",
    "        \n",
    "        Returns:\n",
    "            If return_feats: (B, embed_dim) features\n",
    "            Else: (B, 1) logits\n",
    "        \"\"\"\n",
    "        B = x.shape[0]  # ‚≠ê FIXED: Extract batch size as integer\n",
    "        \n",
    "        # Patch embedding\n",
    "        x = self.patch_embed(x)  # (B, embed_dim, 3, 128)\n",
    "        x = x.flatten(2).transpose(1, 2)  # (B, 384, embed_dim)\n",
    "        \n",
    "        # Add CLS token\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat([cls_tokens, x], dim=1)  # (B, 385, embed_dim)\n",
    "        \n",
    "        # Add position embeddings\n",
    "        x = x + self.pos_embed\n",
    "        \n",
    "        # ---- Transformer blocks with AoL ----\n",
    "        layer_outputs = []\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            layer_outputs.append(x[:, 0])  # CLS token from each layer\n",
    "        \n",
    "        # ---- AoL: Average of all CLS tokens across layers ----\n",
    "        feats = torch.stack(layer_outputs, dim=1).mean(dim=1)  # (B, embed_dim)\n",
    "        x = self.norm(feats)\n",
    "        \n",
    "        if return_feats:\n",
    "            return x\n",
    "        \n",
    "        # Classification\n",
    "        return self.head(x)  # (B, 1)\n",
    "\n",
    "# Initialize model\n",
    "model = ViTClassifier().to(device)\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"ViT Model parameters: {num_params:,}\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "\n",
    "# Sanity check: Forward pass\n",
    "with torch.no_grad():\n",
    "    x_test = torch.randn(2, 3, 24, 2048).to(device)\n",
    "    \n",
    "    # Test logits\n",
    "    logits = model(x_test)\n",
    "    assert logits.shape == (2, 1), f\"Expected (2, 1), got {logits.shape}\"\n",
    "    \n",
    "    # Test features\n",
    "    feats = model(x_test, return_feats=True)\n",
    "    assert feats.shape == (2, 512), f\"Expected (2, 512), got {feats.shape}\"\n",
    "    \n",
    "    print(f\"‚úì Forward pass check passed\")\n",
    "    print(f\"  Logits shape: {logits.shape}, range: [{logits.min():.2f}, {logits.max():.2f}]\")\n",
    "    print(f\"  Features shape: {feats.shape}, range: [{feats.min():.2f}, {feats.max():.2f}]\")\n",
    "\n",
    "print(f\"\\n‚úì Cell 4 completed in {time.time() - cell_start:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a88c94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì FULL MODE: Training for 5 epochs (~2-3 hours)\n",
      "Loss function: BCEWithLogitsLoss with pos_weight=24.81\n",
      "Scheduler: SequentialLR with warmup=2, cosine=3\n",
      "\n",
      "======================================================================\n",
      "Starting training for 5 epochs...\n",
      "  Batch size: 16\n",
      "  Gradient accumulation: 2 steps\n",
      "  Effective batch: 32\n",
      "  AMP enabled: False\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 1.8952 | AUROC: 0.0000 | AUPRC: 0.0000 | F1: 0.1029 | Challenge: 0.5475 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Loss: 1.6700 | AUROC: 0.0000 | AUPRC: 0.0000 | F1: 0.0835 | Challenge: 0.4272 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2277/3162 [46:19<18:35,  1.26s/it, loss=1.83] "
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "# ---- Hyperparameters (adaptive for sample mode) ----\n",
    "if USE_SAMPLE:\n",
    "    num_epochs = 2\n",
    "    print(f\"‚ö†Ô∏è  SAMPLE MODE: Training for {num_epochs} epochs only (~2-3 min)\")\n",
    "else:\n",
    "    num_epochs = 5\n",
    "    print(f\"‚úì FULL MODE: Training for {num_epochs} epochs (~2-3 hours)\")\n",
    "\n",
    "learning_rate = 1e-4\n",
    "warmup_epochs = min(2, num_epochs // 2)\n",
    "use_amp = False  #  FIXED: Disable AMP to avoid conflicts\n",
    "\n",
    "# ---- Optimizer & Loss ----\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=device))\n",
    "print(f\"Loss function: BCEWithLogitsLoss with pos_weight={pos_weight:.2f}\")\n",
    "\n",
    "# ---- Scheduler ----\n",
    "warmup_scheduler = LambdaLR(\n",
    "    optimizer,\n",
    "    lr_lambda=lambda epoch: (epoch + 1) / warmup_epochs if epoch < warmup_epochs else 1.0\n",
    ")\n",
    "\n",
    "cosine_scheduler = CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=max(1, num_epochs - warmup_epochs),\n",
    "    eta_min=learning_rate / 10\n",
    ")\n",
    "\n",
    "scheduler = SequentialLR(\n",
    "    optimizer,\n",
    "    schedulers=[warmup_scheduler, cosine_scheduler],\n",
    "    milestones=[warmup_epochs]\n",
    ")\n",
    "\n",
    "print(f\"Scheduler: SequentialLR with warmup={warmup_epochs}, cosine={max(1, num_epochs - warmup_epochs)}\")\n",
    "\n",
    "# ---- Early Stopping ----\n",
    "patience = 7\n",
    "patience_counter = 0\n",
    "best_val_auc = 0.0\n",
    "best_model_path = EXP_DIR / \"model_best.pth\"\n",
    "\n",
    "# ---- Training Loop ----\n",
    "history = {\n",
    "    'epoch': [],\n",
    "    'train_loss': [],\n",
    "    'val_auc': [],\n",
    "    'val_auprc': [],\n",
    "    'val_f1': [],\n",
    "    'challenge_score': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Starting training for {num_epochs} epochs...\")\n",
    "print(f\"  Batch size: 16\")\n",
    "print(f\"  Gradient accumulation: 2 steps\")\n",
    "print(f\"  Effective batch: 32\")\n",
    "print(f\"  AMP enabled: False\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ---- Train ----\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1:02d}\", leave=False)\n",
    "    \n",
    "    for step, (imgs, labels) in enumerate(train_bar):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device).unsqueeze(1)\n",
    "        \n",
    "        #  SIMPLIFIED: No autocast complexity\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss = loss / 2\n",
    "        loss.backward()\n",
    "        \n",
    "        if (step + 1) % 2 == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        train_loss += loss.item() * 2\n",
    "        train_bar.set_postfix(loss=train_loss / (step + 1))\n",
    "    \n",
    "    train_loss_avg = train_loss / len(train_loader)\n",
    "    \n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_preds, val_trues = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            logits = model(imgs)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy().squeeze()\n",
    "            val_preds.extend(probs if isinstance(probs, np.ndarray) else [probs])\n",
    "            val_trues.extend(labels.numpy())\n",
    "    \n",
    "    val_preds = np.array(val_preds)\n",
    "    val_trues = np.array(val_trues)\n",
    "    \n",
    "    # ---- Metrics ----\n",
    "    try:\n",
    "        val_auc = roc_auc_score(val_trues, val_preds)\n",
    "        val_auprc = average_precision_score(val_trues, val_preds)\n",
    "    except:\n",
    "        val_auc = 0.0\n",
    "        val_auprc = 0.0\n",
    "    \n",
    "    val_trues_bin = (val_trues > 0.5).astype(int)\n",
    "    val_preds_bin = (val_preds >= 0.5).astype(int)\n",
    "    \n",
    "    try:\n",
    "        val_f1 = f1_score(val_trues_bin, val_preds_bin)\n",
    "    except:\n",
    "        val_f1 = 0.0\n",
    "    \n",
    "    if val_trues_bin.sum() > 0:\n",
    "        sorted_idx = np.argsort(val_preds)[::-1]\n",
    "        top_5_pct_idx = max(1, int(0.05 * len(val_preds)))\n",
    "        challenge_score = val_trues_bin[sorted_idx[:top_5_pct_idx]].mean()\n",
    "    else:\n",
    "        challenge_score = 0.0\n",
    "    \n",
    "    # ---- Early stopping ----\n",
    "    improved = \"\"\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        patience_counter = 0\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'epoch': epoch + 1,\n",
    "            'val_auc': val_auc\n",
    "        }, best_model_path)\n",
    "        improved = \"‚úÖ (best)\"\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\n‚ö†Ô∏è  Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    history['epoch'].append(epoch + 1)\n",
    "    history['train_loss'].append(train_loss_avg)\n",
    "    history['val_auc'].append(val_auc)\n",
    "    history['val_auprc'].append(val_auprc)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    history['challenge_score'].append(challenge_score)\n",
    "    history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:02d} | Loss: {train_loss_avg:.4f} | \"\n",
    "          f\"AUROC: {val_auc:.4f} | AUPRC: {val_auprc:.4f} | \"\n",
    "          f\"F1: {val_f1:.4f} | Challenge: {challenge_score:.4f} {improved}\")\n",
    "\n",
    "pd.DataFrame(history).to_csv(EXP_DIR / \"metrics.csv\", index=False)\n",
    "print(f\"\\n‚úì Cell 5 completed in {time.time() - cell_start:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "# ---- Check if model file exists ----\n",
    "if best_model_path.exists():\n",
    "    print(f\"Loading best model from: {best_model_path}\")\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded best model from epoch {checkpoint['epoch']} (Val AUROC: {checkpoint['val_auc']:.4f})\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Model file not found: {best_model_path}\")\n",
    "    print(f\"Using current model state (from last epoch)\")\n",
    "    print(f\"This is normal for quick tests with few epochs\\n\")\n",
    "\n",
    "# Test inference\n",
    "model.eval()\n",
    "test_preds, test_trues = [], []\n",
    "\n",
    "print(f\"\\nRunning test inference on {len(test_ds)} samples...\")\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(test_loader, desc=\"Test\", leave=False)\n",
    "    for imgs, labels in test_bar:\n",
    "        imgs = imgs.to(device)\n",
    "        logits = model(imgs)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy().squeeze()\n",
    "        test_preds.extend(probs if isinstance(probs, np.ndarray) else [probs])\n",
    "        test_trues.extend(labels.numpy())\n",
    "\n",
    "test_preds = np.array(test_preds)\n",
    "test_trues = np.array(test_trues)\n",
    "\n",
    "# Compute metrics\n",
    "test_trues_bin = (test_trues > 0.5).astype(int)\n",
    "test_preds_bin = (test_preds >= 0.5).astype(int)\n",
    "\n",
    "try:\n",
    "    test_auc = roc_auc_score(test_trues_bin, test_preds)\n",
    "    test_auprc = average_precision_score(test_trues_bin, test_preds)\n",
    "except:\n",
    "    test_auc = 0.0\n",
    "    test_auprc = 0.0\n",
    "\n",
    "try:\n",
    "    test_acc = accuracy_score(test_trues_bin, test_preds_bin)\n",
    "    test_f1 = f1_score(test_trues_bin, test_preds_bin)\n",
    "    test_prec = precision_score(test_trues_bin, test_preds_bin, zero_division=0)\n",
    "    test_rec = recall_score(test_trues_bin, test_preds_bin, zero_division=0)\n",
    "except:\n",
    "    test_acc = 0.0\n",
    "    test_f1 = 0.0\n",
    "    test_prec = 0.0\n",
    "    test_rec = 0.0\n",
    "\n",
    "# Challenge score\n",
    "if test_trues_bin.sum() > 0:\n",
    "    sorted_idx = np.argsort(test_preds)[::-1]\n",
    "    top_5_pct_idx = max(1, int(0.05 * len(test_preds)))\n",
    "    challenge_score_test = test_trues_bin[sorted_idx[:top_5_pct_idx]].mean()\n",
    "else:\n",
    "    challenge_score_test = 0.0\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"FINAL TEST RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"AUROC:           {test_auc:.4f}  (target: >0.70)\")\n",
    "print(f\"AUPRC:           {test_auprc:.4f}\")\n",
    "print(f\"Accuracy:        {test_acc:.4f}\")\n",
    "print(f\"F1 Score:        {test_f1:.4f}\")\n",
    "print(f\"Precision:       {test_prec:.4f}\")\n",
    "print(f\"Recall:          {test_rec:.4f}\")\n",
    "print(f\"Challenge Score: {challenge_score_test:.4f}  (target: >0.35)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Save test results\n",
    "test_results = {\n",
    "    'metric': ['AUROC', 'AUPRC', 'Accuracy', 'F1', 'Precision', 'Recall', 'Challenge'],\n",
    "    'value': [test_auc, test_auprc, test_acc, test_f1, test_prec, test_rec, challenge_score_test]\n",
    "}\n",
    "pd.DataFrame(test_results).to_csv(EXP_DIR / \"test_results.csv\", index=False)\n",
    "\n",
    "print(f\"‚úì Cell 6 completed in {time.time() - cell_start:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "# Load history\n",
    "df_hist = pd.DataFrame(history)\n",
    "\n",
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(df_hist['epoch'], df_hist['train_loss'], 'b-o', label='Train')\n",
    "axes[0, 0].set_title('Training Loss', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# AUROC\n",
    "axes[0, 1].plot(df_hist['epoch'], df_hist['val_auc'], 'g-o', label='Val AUROC')\n",
    "axes[0, 1].axhline(0.7, color='r', linestyle='--', label='Target (0.7)')\n",
    "axes[0, 1].set_title('Validation AUROC', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('AUROC')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# AUPRC\n",
    "axes[1, 0].plot(df_hist['epoch'], df_hist['val_auprc'], 'm-o')\n",
    "axes[1, 0].set_title('Validation AUPRC', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('AUPRC')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Challenge Score\n",
    "axes[1, 1].plot(df_hist['epoch'], df_hist['challenge_score'], 'c-o')\n",
    "axes[1, 1].axhline(0.35, color='r', linestyle='--', label='Target (0.35)')\n",
    "axes[1, 1].set_title('Challenge Score (Top 5%)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Score')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(EXP_DIR / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"‚úì Training curves saved\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_trues_bin, test_preds_bin)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(cm, cmap='Blues')\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels(['Negative', 'Positive'])\n",
    "ax.set_yticklabels(['Negative', 'Positive'])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix (Test Set)')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, str(cm[i, j]), ha='center', va='center', color='white', fontsize=16, fontweight='bold')\n",
    "plt.colorbar(im)\n",
    "plt.tight_layout()\n",
    "plt.savefig(EXP_DIR / 'confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"‚úì Confusion matrix saved\")\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(test_trues_bin, test_preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC (AUC={roc_auc:.4f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Chance')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve (Test Set)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(EXP_DIR / 'roc_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"‚úì ROC curve saved\")\n",
    "\n",
    "print(f\"\\n‚úì Cell 7 completed in {time.time() - cell_start:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0973af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "# Create submission CSV\n",
    "submission_df = pd.DataFrame({\n",
    "    'record_id': test_df['id'].values,\n",
    "    'probability': test_preds,\n",
    "    'binary_prediction': test_preds_bin,\n",
    "    'true_label_soft': test_trues,\n",
    "    'true_label_binary': test_trues_bin\n",
    "})\n",
    "\n",
    "submission_df.to_csv(EXP_DIR / 'test_predictions.csv', index=False)\n",
    "print(f\"‚úì Predictions saved to {EXP_DIR / 'test_predictions.csv'}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"  Mean probability: {test_preds.mean():.4f}\")\n",
    "print(f\"  Std probability: {test_preds.std():.4f}\")\n",
    "print(f\"  Min probability: {test_preds.min():.4f}\")\n",
    "print(f\"  Max probability: {test_preds.max():.4f}\")\n",
    "print(f\"  Predicted positive count: {test_preds_bin.sum()} / {len(test_preds)}\")\n",
    "\n",
    "print(f\"\\n‚úì Cell 8 completed in {time.time() - cell_start:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc24a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"FINAL SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"\\nüìä METRICS ACHIEVED:\")\n",
    "print(f\"  ‚úì Test AUROC:           {test_auc:.4f} (target: >0.70)\")\n",
    "print(f\"  ‚úì Test AUPRC:           {test_auprc:.4f}\")\n",
    "print(f\"  ‚úì Test Challenge Score: {challenge_score_test:.4f} (target: >0.35)\")\n",
    "\n",
    "if test_auc >= 0.70:\n",
    "    print(f\"  ‚úÖ AUROC TARGET ACHIEVED!\")\n",
    "else:\n",
    "    print(f\"  ‚ö†Ô∏è  AUROC below target.\")\n",
    "\n",
    "if challenge_score_test >= 0.35:\n",
    "    print(f\"  ‚úÖ CHALLENGE SCORE TARGET ACHIEVED!\")\n",
    "else:\n",
    "    print(f\"  ‚ö†Ô∏è  Challenge score below target.\")\n",
    "\n",
    "print(f\"\\nüìÅ OUTPUTS SAVED:\")\n",
    "print(f\"  ‚Ä¢ {best_model_path}\")\n",
    "print(f\"  ‚Ä¢ {EXP_DIR / 'metrics.csv'}\")\n",
    "print(f\"  ‚Ä¢ {EXP_DIR / 'test_results.csv'}\")\n",
    "print(f\"  ‚Ä¢ {EXP_DIR / 'test_predictions.csv'}\")\n",
    "print(f\"  ‚Ä¢ {EXP_DIR / 'training_curves.png'}\")\n",
    "print(f\"  ‚Ä¢ {EXP_DIR / 'confusion_matrix.png'}\")\n",
    "print(f\"  ‚Ä¢ {EXP_DIR / 'roc_curve.png'}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"‚ú® All cells completed successfully!\")\n",
    "print(f\"{'='*70}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
