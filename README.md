ğŸ“Œ 1. Project Overview

ChagaSight is a modular deep-learning research framework designed to investigate whether Vision Transformers, when trained on physiologically meaningful ECG image representations, can effectively detect Chagas disease across multiple ECG datasets.

The project places primary emphasis on:

Transforming raw 12-lead ECG signals into structured 2D images and preparing a Vision Transformer classifier for disease detection.

In addition, the architecture is designed to support future extensions, including 1D ECG foundation models and hybrid alignment strategies. These extensions are explicitly marked as optional and non-essential for the core dissertation contribution.

ğŸ“š Research Inspiration

The design of ChagaSight is informed by two contemporary ECG-AI research directions:

Physiologically Structured 2D ECG Image Embedding (2025)
â€” converting ECG signals into spatially structured image representations.

Vision Transformerâ€“Based ECG Foundation Models (2025)
â€” applying transformer architectures to ECG signals using self-supervised learning.

These works inspire architectural choices, but the implementation focuses on a practical, verifiable, and reproducible pipeline suitable for academic evaluation.

ğŸ“Š 2. Supported Datasets

ChagaSight currently supports three widely used 12-lead ECG datasets in modern ECG research.

Dataset Description Sample Rate Chagas Label
PTB-XL European clinical ECG dataset (~21k recordings) 100 / 500 Hz All negative (0)
CODE-15% Brazilian population ECG cohort 400 Hz Soft labels: 0.2 / 0.8
SaMi-Trop Serology-confirmed Chagas cohort 400 Hz All positive (1)
âœ” Label Policy

The following labeling strategy is adopted in line with state-of-the-art ECG-AI research:

Dataset Confidence Label Assignment
PTB-XL Very strong negative 0
SaMi-Trop Very strong positive 1
CODE-15% Weak / self-reported Soft labels (0.2 / 0.8)
ğŸ“ 3. Project Folder Structure

The structure below represents the logical system architecture.
Large datasets and virtual-environment internals are intentionally excluded.

ChagaSight/
â”œâ”€â”€ .git/
â”œâ”€â”€ .venv/ # Python virtual environment (ignored in version control)
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Original unmodified ECG datasets
â”‚ â”‚ â”œâ”€â”€ ptbxl/
â”‚ â”‚ â”œâ”€â”€ code15/
â”‚ â”‚ â””â”€â”€ sami_trop/
â”‚ â”‚
â”‚ â”œâ”€â”€ processed/
â”‚ â”‚ â”œâ”€â”€ 1d_signals_100hz/ # FM-compatible 1D ECG signals
â”‚ â”‚ â”œâ”€â”€ 1d_signals_500hz/ # High-resolution signals for image embedding
â”‚ â”‚ â”œâ”€â”€ 2d_images/ # Structured ECG image representations
â”‚ â”‚ â””â”€â”€ metadata/ # Processed dataset metadata (CSV)
â”‚ â”‚
â”‚ â””â”€â”€ splits/ # Train / validation / test splits
â”‚
â”œâ”€â”€ notebooks/ # Exploratory analysis and development notebooks
â”‚
â”œâ”€â”€ scripts/ # Dataset-level preprocessing scripts
â”‚ â”œâ”€â”€ preprocess_ptbxl.py
â”‚ â”œâ”€â”€ preprocess_code15.py
â”‚ â”œâ”€â”€ preprocess_code15_corrected.py
â”‚ â”œâ”€â”€ preprocess_samitrop.py
â”‚ â”œâ”€â”€ preprocess_samitrop_updated.py
â”‚ â”œâ”€â”€ build_images.py
â”‚ â””â”€â”€ validate_single_ecg.py
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ preprocessing/ # Core ECG signal processing modules
â”‚ â”‚ â”œâ”€â”€ baseline_removal.py
â”‚ â”‚ â”œâ”€â”€ resample.py
â”‚ â”‚ â”œâ”€â”€ normalization.py
â”‚ â”‚ â”œâ”€â”€ image_embedding.py
â”‚ â”‚ â””â”€â”€ soft_labels.py
â”‚ â”‚
â”‚ â”œâ”€â”€ dataloaders/
â”‚ â”‚ â””â”€â”€ ptbxl_loader.py
â”‚ â”‚
â”‚ â”œâ”€â”€ image_model/ # Image-based model components (planned)
â”‚ â”œâ”€â”€ foundation_model/ # Optional FM architecture (design stage)
â”‚ â”œâ”€â”€ training/ # Training orchestration (planned)
â”‚ â””â”€â”€ evaluation/ # Evaluation utilities (planned)
â”‚
â”œâ”€â”€ tests/ # Scientific verification & validation suite
â”‚ â”œâ”€â”€ test_baseline.py
â”‚ â”œâ”€â”€ test_resample.py
â”‚ â”œâ”€â”€ test_preprocessing_pipeline.py
â”‚ â”œâ”€â”€ test_samitrop_preprocessing.py
â”‚ â”œâ”€â”€ test_code15_raw.py
â”‚ â”œâ”€â”€ analyze_samitrop_signals.py
â”‚ â”œâ”€â”€ check_raw_data.py
â”‚ â”œâ”€â”€ validate_single_ecg.py
â”‚ â””â”€â”€ verification_outputs/
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

ğŸ”§ 4. ECG Preprocessing Pipeline

ChagaSight adopts a two-stage preprocessing strategy, fully implemented and verified through scripts and tests.

Stage 1 â€” 1D ECG Signal Preprocessing (Implemented)

The following steps are applied in a dataset-aware manner:

Baseline drift removal

Resampling to a unified frequency

Padding or trimming to a fixed duration (10 seconds)

Per-lead z-score normalization

Saving processed signals as .npy arrays

Dataset-specific baseline handling:

PTB-XL â†’ band-pass filtering (0.5â€“45 Hz)

SaMi-Trop â†’ moving-average baseline removal

CODE-15% â†’ no baseline removal (pre-filtered data)

Output directories:

data/processed/1d_signals_500hz/
data/processed/1d_signals_100hz/

Stage 2 â€” ECG â†’ Structured 2D Image Conversion (Implemented)

Each ECG is converted into a physiologically structured image using limb-lead reference mapping:

Construction of three channels representing RA, LA, and LL contours

Subtraction of augmented limb-lead reference

Amplitude clipping to [-3, 3]

Linear scaling to [0, 255]

Resizing to 3 Ã— 24 Ã— 2048

Output directory:

data/processed/2d_images/

This representation is optimised for Vision Transformer input.

ğŸ§  5. Model Scope
A. Vision Transformer (Primary Dissertation Model)

Input: structured 2D ECG images

Architecture: Vision Transformer adapted for rectangular biomedical images

Output: probability of Chagas disease

Status:
Model training and evaluation constitute the next planned project phase.

B. ECG Foundation Model (Optional Research Extension)

An optional architectural extension is designed for a 1D ECG Foundation Model, inspired by masked self-supervised learning (e.g. ST-MEM).

Status:
Design exploration only.
Not required for core dissertation results.

C. Hybrid FM + ViT Alignment (Future Research Direction)

A proposed hybrid model aims to align 1D FM embeddings with 2D ViT embeddings using a cosine-similarityâ€“based objective.

Status:
Conceptual design only.

ğŸ§ª 6. Training & Validation Workflow
Implemented

1D ECG preprocessing (scripts/preprocess\_\*.py)

ECG â†’ 2D image generation (scripts/build_images.py)

Pipeline validation (tests/validate_single_ecg.py)

Validation includes:

Signal integrity checks

Frequency-domain inspection

Lead-wise consistency analysis

1D â†” 2D correspondence

Planned

Vision Transformer training

Model evaluation and explainability

ğŸ“ˆ 7. Evaluation Metrics (Planned)

AUROC

AUPRC

Accuracy

F1-score

Calibration curves

Confusion matrices

Explainability techniques (e.g. Grad-CAM) are planned for future evaluation.

ğŸ” 8. Key Contributions
âœ” Implemented

Physiologically structured 2D ECG image pipeline

Unified multi-dataset preprocessing

Comprehensive verification and validation suite

â—» Planned

Vision Transformer classifier training

Performance evaluation and explainability

Optional foundation-model experiments

ğŸš€ 9. Roadmap

1D ECG preprocessing

Structured 2D image generation

Validation & verification

Vision Transformer training

Model evaluation & explainability

Dissertation writing & submission

ğŸ“¦ Reproducibility

All dependencies are defined in:

requirements.txt

A Python virtual environment (.venv/) is used locally and excluded from version control.

ğŸ“¬ Contact

Refer to the tests/ and notebooks/ directories for validation outputs, diagnostic plots, and exploratory analyses supporting the methodology.
